{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c954c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nim_qlearner 1000\n",
      "nim_qlearner 3\n",
      "1000 games, Qlearner  497    Random  503\n",
      "nim_qlearner 10\n",
      "1000 games, Qlearner  574    Random  426\n",
      "nim_qlearner 100\n",
      "1000 games, Qlearner  710    Random  290\n",
      "nim_qlearner 1000\n",
      "1000 games, Qlearner  922    Random   78\n",
      "nim_qlearner 10000\n",
      "1000 games, Qlearner  984    Random   16\n",
      "nim_qlearner 5000\n",
      "1000 games, Qlearner  979    Random   21\n",
      "nim_qlearner 100000\n",
      "1000 games, Qlearner  996    Random    4\n",
      "1000 games, Qlearner  999    Random    1\n",
      "1000 games,   Random   15  Qlearner  985\n",
      "1000 games,   Random  506    Random  494\n",
      "1000 games, Qlearner  927      Guru   73\n",
      "[0.497, 0.574, 0.71, 0.922, 0.984, 0.979, 0.996]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from random import randint, choice\n",
    "\n",
    "qtable, Alpha, Gamma, Reward = None, 0.1, 0.75, 42.0\n",
    "\n",
    "# The number of piles is 3\n",
    "\n",
    "# max number of items per pile\n",
    "ITEMS_MX = 10\n",
    "\n",
    "# Initialize starting position\n",
    "def init_game():\n",
    "    return [randint(1,ITEMS_MX), randint(1,ITEMS_MX), randint(1,ITEMS_MX)]\n",
    "\n",
    "# Based on X-oring the item counts in piles - mathematical solution\n",
    "def nim_guru(st):\n",
    "    xored = st[0] ^ st[1] ^ st[2]\n",
    "    if xored == 0:\n",
    "        return nim_random(st)\n",
    "    #\n",
    "    for pile in range(3):\n",
    "        s = st[pile] ^ xored\n",
    "        if s <= st[pile]:\n",
    "            return st[pile]-s, pile\n",
    "\n",
    "# Random Nim player\n",
    "def nim_random(_st):\n",
    "    pile = choice([i for i in range(3) if _st[i]>0])  # find the non-empty piles\n",
    "    return randint(1, _st[pile]), pile  # random move\n",
    "\n",
    "def nim_qlearner(_st):\n",
    "    # pick the best rewarding move, equation 1\n",
    "    a = np.argmax(qtable[_st[0], _st[1], _st[2]])  # exploitation\n",
    "    # index is based on move, pile\n",
    "    move, pile = a%ITEMS_MX+1, a//ITEMS_MX\n",
    "    # check if qtable has generated a random but game illegal move - we have not explored there yet\n",
    "    if move <= 0 or _st[pile] < move:\n",
    "        move, pile = nim_random(_st)  # exploration\n",
    "\n",
    "    return move, pile  # action\n",
    "\n",
    "Engines = {'Random':nim_random, 'Guru':nim_guru, 'Qlearner':nim_qlearner}\n",
    "\n",
    "def game(a, b):\n",
    "    state, side = init_game(), 'A'\n",
    "    while True:\n",
    "        engine = Engines[a] if side == 'A' else Engines[b]\n",
    "        move, pile = engine(state)\n",
    "        # print(state, move, pile)  # debug purposes\n",
    "        state[pile] -= move\n",
    "        if state == [0, 0, 0]:  # game ends\n",
    "            return side  # winning side\n",
    "\n",
    "        side = 'B' if side == 'A' else 'A'  # switch sides\n",
    "\n",
    "def play_games(_n, a, b):\n",
    "    from collections import defaultdict\n",
    "    wins = defaultdict(int)\n",
    "    for i in range(_n):\n",
    "        wins[game(a, b)] += 1\n",
    "    # info\n",
    "    print(f\"{_n} games, {a:>8s}{wins['A']:5d}  {b:>8s}{wins['B']:5d}\")\n",
    "\n",
    "    return wins['A'], wins['B']\n",
    "\n",
    "def game(a, b):\n",
    "    state, side = init_game(), 'A'\n",
    "    while True:\n",
    "        engine = Engines[a] if side == 'A' else Engines[b]\n",
    "        move, pile = engine(state)\n",
    "        # print(state, move, pile)  # debug purposes\n",
    "        state[pile] -= move\n",
    "        if state == [0, 0, 0]:  # game ends\n",
    "            return side  # winning side\n",
    "\n",
    "        side = 'B' if side == 'A' else 'A'  # switch sides\n",
    "\n",
    "def play_games(_n, a, b):\n",
    "    from collections import defaultdict\n",
    "    wins = defaultdict(int)\n",
    "    for i in range(_n):\n",
    "        wins[game(a, b)] += 1\n",
    "    # info\n",
    "    print(f\"{_n} games, {a:>8s}{wins['A']:5d}  {b:>8s}{wins['B']:5d}\")\n",
    "\n",
    "    return wins['A'], wins['B']\n",
    "\n",
    "# Function to print the entire set of states\n",
    "def qtable_log(_fn):\n",
    "    with open(_fn, 'w') as fout:\n",
    "        s = 'state'\n",
    "        for a in range(ITEMS_MX*3):\n",
    "            move, pile = a%ITEMS_MX+1, a//ITEMS_MX\n",
    "            s += ',%02d_%01d' % (move,pile)\n",
    "\n",
    "        print(s, file=fout)\n",
    "        for i, j, k in [(i,j,k) for i in range(ITEMS_MX+1) for j in range(ITEMS_MX+1) for k in range(ITEMS_MX+1)]:\n",
    "            s = '%02d_%02d_%02d' % (i,j,k)\n",
    "            for a in range(ITEMS_MX*3):\n",
    "                r = qtable[i, j, k, a]\n",
    "                s += ',%.1f' % r\n",
    "\n",
    "            print(s, file=fout)\n",
    "            \n",
    "            \n",
    "# learn from _n games, randomly played to explore the possible states\n",
    "def nim_qlearn(_n):\n",
    "    print(\"nim_qlearner \" + str(_n))\n",
    "    global qtable\n",
    "    # based on max items per pile\n",
    "    qtable = np.zeros((ITEMS_MX+1, ITEMS_MX+1, ITEMS_MX+1, ITEMS_MX*3), dtype=float)\n",
    "    \n",
    "    qtable_log('qtable_debug0.txt')\n",
    "\n",
    "    # play _n games\n",
    "    for i in range(_n):\n",
    "        # track all moves for the game\n",
    "        movesA = []\n",
    "        movesB = []\n",
    "        turn = 'A'\n",
    "        a, b = 'Qlearner', 'Qlearner'\n",
    "        # first state is starting position\n",
    "        st1 = init_game()\n",
    "        while True:  # while game not finished\n",
    "            engine = Engines[a] if turn == 'A' else Engines[b]\n",
    "            # make a random move - exploration\n",
    "            #move, pile = nim_random(st1)\n",
    "            #move, pile = nim_qlearner(st1)\n",
    "            move, pile = engine(st1)\n",
    "\n",
    "            st2 = list(st1)\n",
    "            # make the move\n",
    "            st2[pile] -= move  # --> last move I made\n",
    "\n",
    "\n",
    "            r = qtable[st2[0], st2[1], st2[2]]\n",
    "            if turn == 'A':\n",
    "                movesA.append((move, pile, list(st1), r))\n",
    "            if turn == 'B':\n",
    "                movesB.append((move, pile, list(st1), r))\n",
    "\n",
    "            if st2 == [0, 0, 0]:  # game ends\n",
    "                good_moves = movesA if turn == 'A' else movesB\n",
    "                bad_moves = movesA if turn == 'B' else movesB\n",
    "                \n",
    "                # qtable_update(Reward, st1, move, pile, 0)  # I won\n",
    "\n",
    "                for j in range(len(good_moves)):\n",
    "                    stx = good_moves[j][2]\n",
    "                    qtable_update(Reward, stx, good_moves[j][0], good_moves[j][1])  # I won\n",
    "                \n",
    "                for j in range(len(bad_moves)):\n",
    "                    stx = bad_moves[j][2]\n",
    "                    qtable_update(-Reward, stx, bad_moves[j][0], bad_moves[j][1])  # I lost\n",
    "                \n",
    "                break  # new game\n",
    "\n",
    "            \n",
    "            # let's just save how \"good\" that move was\n",
    "            # qtable_update(0, st1, move, pile, np.max(qtable[st2[0], st2[1], st2[2]]))\n",
    "            st1 = st2\n",
    "            turn = 'B' if turn == 'A' else 'A'\n",
    "    qtable_log('qtable_debug'+str(_n)+'.txt')\n",
    "\n",
    "# Equation 3 - update the qtable\n",
    "def qtable_update(r, _st1, move, pile): #, q_future_best):\n",
    "    a = pile*ITEMS_MX+move-1\n",
    "    q_future_best = qtable[_st1[0], _st1[1], _st1[2], a]\n",
    "    qtable[_st1[0], _st1[1], _st1[2], a] = Alpha * (r + Gamma * q_future_best)\n",
    "\n",
    "nim_qlearn(1000)\n",
    "\n",
    "\n",
    "n_train = (3, 10, 100, 1000, 10000, 5000, 100000)\n",
    "wins = []\n",
    "for n in n_train:\n",
    "    nim_qlearn(n)\n",
    "    a, b = play_games(1000, 'Qlearner', 'Random')\n",
    "    wins += [a/(a+b)]\n",
    "\n",
    "# Play games\n",
    "play_games(1000, 'Qlearner', 'Random')\n",
    "play_games(1000, 'Random', 'Qlearner')\n",
    "play_games(1000, 'Random', 'Random') \n",
    "play_games(1000, 'Qlearner', 'Guru')\n",
    "\n",
    "print(wins)\n",
    "\n",
    "qtable_log('qtable_debug.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4bbad",
   "metadata": {},
   "source": [
    "Key findings:\n",
    "\n",
    "- qtable_update is using the exact value at the place it's updating, instead of random \"next move\" argument\n",
    "- fine tuning the parameters (making alpha lower, gamma higher and changing the reward)\n",
    "- Making the QLearner train with itself instead of random agent, and being player 1 (since it has the advantage).\n",
    "\n",
    "To test it, the function play_games was used with QLearner being player 1 and Guru player 2, resulting in winning most games, making it possible for QLearner agent to beat the Guru agent.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb0ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
